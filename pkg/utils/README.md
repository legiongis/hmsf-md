### Creating Thesauri and Concept Collections From CSVs

**This is an old workflow, hasn't been tested or used recently! AC - Jan 28th, 2023

##### Step 1

create CSV files in a dedicated directory, per thesaurus (i.e. if you have two separate sets of the CSVs from which you want to make two separate thesauri, place each set in its own directory). note that no header rows were used in the development of the following scripts, but untested support for header rows has been attempted.

##### Step 2

add UUIDs to the CSV files

+ run command
        python add_uuid_to_csvs.py <csv directory> [-s/--safe]
        
will add a new column to the csv files and populate it with new UUIDs. if this column exists already, no new column will be added and the existing values will remain unchanged. currently the testing for this happens on a per-column basis, which means that if a new value is added to the end of a CSV that already has UUIDs in it, no new UUID will be added to that row, as the entire file will be skipped when the column first encountered (this could be improved...).

add the `-s/--safe` boolean argument to place the resulting files into a new directory, instead of overwriting the original files.
        
##### Step 3

create thesaurus from each directory full of CSVs. at the same time, a collections file is also made. each csv is treated as a top concept with descendent concepts. accordingly, a collection is created for each csv and all of the concepts that are generated by the csv are added to that collection. thus, the result is really two files, a thesaurus file and a collections file, named <csv directory>-thesaurus.xml and <csv directory>-collections.xml.

+ run command
        python thesaurus_from_csvs.py <csv directory> [-m/--mock]
        
will process the input directory and create a thesaurus and collections file, as described above. add the `-m/--mock` argument to create mock UUIDs throughout the whole new thesaurus. this may be useful for debugging, but does not created a valid thesaurus.

Note that not all of the options have properly been moved to argparse yet, so you will need to edit some stuff within the script itself. 

+ you can specify which files have contents that should be sorted alphabetically (otherwise a sortorder is added to concepts to recreate their original order in the csv files).
+ the output directory is generated by the script, and you may need to edit it manually.
+ you can change what column the script will use for the new preflabels for the concepts, and which column holds the UUIDs (this must be the same for all csvs, however you can use index references, so `:-1` will specify the last column in each csv, regardless of the number of columns therein.

very importantly, if the thesaurus/collections files exist before the script is made, then the topconcept uuids and collections uuids will be retrieved from them instead of being regenerated. this is necessary as resources models may reference collection ids so those must remain constant, and if new topconceptids are created, you will double all of your existing top concepts, even if you load the concepts with `-ow overwrite`.

### Updates to HMS from FMSF

This entire process is now handled with the fmsf2hms QGIS plugin: [legiongis/fmsf2hms](https://github.com/legiongis/fmsf2hms).
Full documentation for the plugin is [here](https://www.notion.so/legiongis/FMSF-to-HMS-QGIS-Plugin-1a413cd8aa334e9bb2180be8c6841665).
